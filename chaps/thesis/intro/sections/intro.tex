% !TEX root = ../main.tex

La simulation numérique fut introduite dès l’émergence de l’informatique pour enrichir les connaissances scientifiques dans des contextes où l’expérimentation est trop contraignante voire impossible. La simulation peut aussi avoir un intérêt prédictif pour dimensionner un problème physique (simulation de tokamak avant leur construction dans le projet ITER) ou pour tester un modèle et le confronter aux futures observations (simulation de nébuleuses ou d’étoiles). La simulation peut être vue comme une retranscription informatique de modèles mathématiques, censés représenter des phénomènes physiques. La simulation numérique doit être représentative de la réalité. Ainsi, dans des modèles où la solution exacte est souvent hors de portée, il est nécessaire de vérifier que la transcription numérique conserve certaines propriétés mathématiques du modèle (conservation de certaines quantités physiques comme la masse ou l’énergie totale par exemple).

Un enjeu majeur de la modélisation et de la simulation est de maintenir un équilibre entre les approximations au niveau du modèle, qui permettent d’accélérer le temps de traitement et la précision des résultats.

Les modèles étudiés ici sont des modèles issus de la physique des plasmas. Un plasma désigne un gaz ionisé constitué généralement d'ions et d'électrons. Le terme plasma a été introduit par le chimise et physicien américain Irving Lagmuir en 1928, par analogie avec le plasma sanguin. À la différence d'un gaz, consituté de particules neutres et dont la dynamique peut être modélisé par les équations de Navier-Stockes ou un modéle dérivé, un plasma est sensible à l'action d'un champ électromagnétique. Le mouvement des particules chargées du plasma est déterminé par le champ électromagnétique, via la force de Lorentz ; le champ électromagnétique étant induit par la distribution des particules en position (densité) et en vitesse (courant).

Pour décrire un tel système de particules, plusieurs possibilités existent. La description dite fluide, qui prend en compte les équations de la mécanique des fluides (comme les équations d’Euler ou de Navier-Stokes) peut être utilisée. Les inconnues de ces équations sont des quantités dites macroscopiques (mesurables expérimentalement) comme la densité, la vitesse moyenne ou la température qui ne dépendent que du temps et de la position. Cependant cette description suppose que le système étudié est à l’équilibre, c’est-à-dire que la répartition en vitesse des particules est maxwellienne. Or lorsque le système est parcouru par une onde de choc ou lorsqu’une population de particules chaudes est présente dans le système, des phénomènes hors équilibre sont à prendre en compte exigeant une description plus précise. On utilise alors la description cinétique. Celle-ci manipule une fonction de distribution dépendant du temps, de l’espace mais aussi de la vitesse des particules, ce qui permet de prendre en compte ces aspects hors équilibre. La complexité de description apportée par le modèle cinétique se traduit numériquement par un coût en temps de calcul et utilisation de la mémoire ; en effet la simulation s’effectue avec les variables $(t,x,v)$ donc 7 dimensions au lieu de seulement 4 dimensions pour la description fluide, où les inconnues ne dépendent que de $(t,x)$. L’espace mémoire nécessaire pour stocker $f(t=0,x,v)$ sur une grille $100^6$ de l’espace des phases peut être estimé à 7.2To, alors que la description fluide ne nécessite que 7.6Mo sur une grille $100^3$ de l’espace. Une description cinétique n’est donc pas souhaitable sur tout le domaine d’étude si le fluide est proche de son équilibre et des optimisations sont donc envisageables dans ce type de configuration. Nous nous intéresserons ici à des modélisations hybrides, où une population de particules, dites \emph{froides}, sont proches de l'équilibre, ce qui permettra de relaxer une contrainte sur la maillage en vitesse, comme nous le verons dans le chapitre~\ref{chap2}.
